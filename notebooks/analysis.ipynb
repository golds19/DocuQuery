{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98cf4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the libraries\n",
    "from dotenv import load_dotenv\n",
    "import pymupdf\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fb928cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# set the embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec0ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a class for extracting text from documents\n",
    "class PdfExtractors:\n",
    "    def __init__(self, pdf_path: str):\n",
    "        self.pdf_path = pdf_path\n",
    "\n",
    "    def extract_text_from_pdf(self) -> str:\n",
    "        \"\"\"Extract text directly from PDF pages.\"\"\"\n",
    "        try:\n",
    "            doc = pymupdf.open(self.pdf_path)\n",
    "            text_parts = []\n",
    "            for page in doc:\n",
    "                text_parts.append(page.get_text())\n",
    "            doc.close()\n",
    "            return \"\".join(text_parts)\n",
    "        except FileNotFoundError:\n",
    "            return f\"Error: PDF file '{self.pdf_path}' not found.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting text from PDF: {str(e)}\"\n",
    "\n",
    "    def extract_text_from_images(self) -> str:\n",
    "        \"\"\"Extract text from images in a PDF using OCR.\"\"\"\n",
    "        try:\n",
    "            images = convert_from_path(self.pdf_path)\n",
    "            text_from_images = []\n",
    "            for img in images:\n",
    "                text = pytesseract.image_to_string(img)\n",
    "                text_from_images.append(text)\n",
    "            return \"\\n\".join(text_from_images)\n",
    "        except FileNotFoundError:\n",
    "            return f\"Error: PDF file '{self.pdf_path}' not found.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting text from images: {str(e)}\"\n",
    "\n",
    "    def extract_from_jpg(self, image_path: str) -> str:\n",
    "        \"\"\"Extract text from a single JPG image using OCR.\"\"\"\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            text = pytesseract.image_to_string(img)\n",
    "            img.close()\n",
    "            return text\n",
    "        except FileNotFoundError:\n",
    "            return f\"Error: Image file '{image_path}' not found.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error extracting text from image: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca852cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking and storing extracted text\n",
    "\n",
    "def load_and_chunk_pdfs_and_images(pdf_paths, images_paths, chunk_size=500, chunk_overlap=50):\n",
    "    documents = []\n",
    "\n",
    "    # process PDFs\n",
    "    for pdf_path in pdf_paths:\n",
    "        pdf_extractor = PdfExtractors(pdf_path)\n",
    "        try:\n",
    "            pdf_text = pdf_extractor.extract_text_from_pdf()\n",
    "            if pdf_text:\n",
    "                documents.append(Document(page_content=pdf_text, metadata={\"source\": pdf_path, \"type\": \"pdf\"}))\n",
    "            else:\n",
    "                pdf_text_from_images = pdf_extractor.extract_text_from_images()\n",
    "                documents.append(Document(page_content=pdf_text_from_images, metadata={\"source\": pdf_path, \"type\": \"pdf\"}))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF {pdf_path}: {e}\")\n",
    "\n",
    "    # Process JPG images\n",
    "    for image_path in images_paths:\n",
    "        try:\n",
    "            # Use PdfExtractors instance to extract text from JPG\n",
    "            pdf_extractor = PdfExtractors(\"\")  # Dummy path since extract_from_jpg doesn't use pdf_path\n",
    "            image_text = pdf_extractor.extract_from_jpg(image_path)\n",
    "            if not image_text.startswith(\"Error\"):\n",
    "                documents.append(Document(page_content=image_text, metadata={\"source\": image_path, \"type\": \"jpg\"}))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "    \n",
    "    # chunk the documents into manageable pieces\n",
    "    chunked_documents = []\n",
    "    for doc in documents:\n",
    "        text = doc.page_content\n",
    "        for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "            chunk = text[i:i+chunk_size]\n",
    "            chunked_documents.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "\n",
    "    return chunked_documents\n",
    "\n",
    "def documents_storing_in_vectorDB(documents):\n",
    "    try:\n",
    "        # setting the vectore store\n",
    "        PineconeVectorStore.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            index_name=\"ocr-rag\"\n",
    "        )\n",
    "        print(f\"Documents stored successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Documents storing failed: {e}\")\n",
    "\n",
    "\n",
    "# examples\n",
    "pdf_paths = [\"C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf\", \"C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/rent_receipt.pdf\",\"C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/docu-tracking-ai-in-10-charts.pdf\"]\n",
    "images_paths = [\"C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/image_test1.png\", \"C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/image_test2.png\" ]\n",
    "\n",
    "# load and chunk the PDFs and images\n",
    "documents = load_and_chunk_pdfs_and_images(pdf_paths, images_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc19da47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='  \\n \\n \\nPage 1 of 2\\nCREDIT CARD / ACH PAYMENT AUTHORIZATION \\n \\n \\nCheck One (1) and Enter Your Details \\n \\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  \\n \\n☐ - Recurring Charge - You authorize regularly scheduled charges to your credit card \\nor bank account. You will be charged the amount indicated below each billing period. A \\nreceipt for each payment will be provided to you and the charge will appear on your \\ncredi'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='d to you and the charge will appear on your \\ncredit card or bank statement. You agree that no prior notification will be provided \\nunless the date or amount changes, in which case you will receive notice from us at \\nleast 10 days prior to the payment being collected. \\n \\nI, _______________________, authorize _________________________ to charge my  \\n                      (Full Name)                                                       (Merchant’s Name) \\n \\nCredit Card or Bank Account below for $__'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='Name) \\n \\nCredit Card or Bank Account below for $________________ on the ______________  \\n                                                                                        (Amount $)                                     (day) \\nof each ________________. \\n               (week, month, etc.) \\n \\nThis payment is for ________________________________. \\n                                          (Description of Goods/Services) \\n \\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - '),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  \\n \\n☐ - One (1) Time Charge – Sign and complete this form to authorize the merchant \\nbelow to make a one-time charge to your credit card or bank account listed below.   \\n \\nBy signing this form, you give us permission to debit your account for the amount \\nindicated on or after the indicated date. This is permission for a single transaction only, \\nand does not provide authorization for any add'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='y, \\nand does not provide authorization for any additional unrelated debits or credits to your \\naccount. \\n \\nI, _______________________, authorize _________________________ to charge my  \\n                      (Full Name)                                                       (Merchant’s Name) \\n \\ncredit card or bank account indicated below for $_______________ on ____________.   \\n                                                                                                      (Amount $)        '),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='                                (Amount $)                          (Date) \\n \\nThis payment is for ________________________________. \\n                                          (Description of Goods/Services) \\n \\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  \\n \\n \\n \\nPage 2 of 2\\nBilling Information \\nBilling Address ___________________________   Phone # ______________________ \\nCity, State, Zip __________________________'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='_____ \\nCity, State, Zip ___________________________   Email ________________________  \\nBank (ACH) \\n Credit Card \\n☐Checking\\n☐Savings\\nName on Acct \\n_______________\\nBank Name \\n_______________\\nAccount Number \\n_______________\\nRouting Number \\n_______________\\n☐Visa\\n☐MasterCard\\n☐Amex\\n☐Discover\\nCardholder Name \\n_______________\\nAccount Number \\n_______________\\nExp. Date \\n_______ / _______\\nCVV  \\n  _______ \\nI understand that this authorization will remain in effect until I cancel it in writing, and I agree t'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='effect until I cancel it in writing, and I agree to notify the \\nmerchant in writing of any changes in my account information or termination of this authorization at least \\n15 days prior to the next billing date. If the above noted payment dates fall on a weekend or holiday, I \\nunderstand that the payments may be executed on the next business day. For ACH debits to my \\nchecking/savings account, I understand that because these are electronic transactions, these funds may \\nbe withdrawn from my acco'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='ctions, these funds may \\nbe withdrawn from my account as soon as the above noted periodic transaction dates. In the case of an \\nACH Transaction being rejected for Non-Sufficient Funds (NSF) I understand that the merchant may at its \\ndiscretion attempt to process the charge again within 30 days, and agree to an additional $_____ charge \\nfor each attempt returned NSF which will be initiated as a separate transaction from the authorized \\nrecurring payment. I acknowledge that the origination of ACH '),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content='ayment. I acknowledge that the origination of ACH transactions to my account must comply \\nwith the provisions of U.S. law. I certify that I am an authorized user of this credit card/bank account and \\nwill not dispute these scheduled transactions with my bank or credit card company; so long as the \\ntransactions correspond to the terms indicated in this authorization form.  \\nAUTHORIZED SIGNATURE ___________________________ DATE _____________ \\nPRINT NAME ___________________________ \\n'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/credit.pdf', 'type': 'pdf'}, page_content=' NAME ___________________________ \\n'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/rent_receipt.pdf', 'type': 'pdf'}, page_content=' \\nRENT RECEIPT \\n  \\nDate  \\n   \\n  \\nNo. \\n \\nReceived from  \\nThe Sum of    \\n \\n  \\n  \\nDollars \\n \\n  \\n \\nFor Rent at  \\nPaid by  ☐ Check No. \\n  \\n \\n  \\n☐ Cash \\n \\nFor the Period  \\nto \\n☐ Money Order \\n \\nReceived by  \\n \\nAddress  \\n \\n \\n \\nPhone  \\n \\nLandlord’s Signature \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRENT RECEIPT \\n  \\nDate  \\n   \\n  \\nNo. \\n \\nReceived from  \\nThe Sum of    \\n \\n  \\n  \\nDollars \\n \\n  \\n \\nFor Rent at  \\nPaid by  ☐ Check No. \\n  \\n \\n  \\n☐ Cash \\n \\nFor the Period  \\nto \\n☐ Money Order \\n \\nReceived by  \\n \\nAddress  \\n \\n \\n \\nPhone  \\n \\nLa'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/rent_receipt.pdf', 'type': 'pdf'}, page_content='er \\n \\nReceived by  \\n \\nAddress  \\n \\n \\n \\nPhone  \\n \\nLandlord’s Signature \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRENT RECEIPT \\n  \\nDate  \\n   \\n  \\nNo. \\n \\nReceived from  \\nThe Sum of    \\n \\n  \\n  \\nDollars \\n \\n  \\n \\nFor Rent at  \\nPaid by  ☐ Check No. \\n  \\n \\n  \\n☐ Cash \\n \\nFor the Period  \\nto \\n☐ Money Order \\n \\nReceived by  \\n \\nAddress  \\n \\n \\n \\nPhone  \\n \\nLandlord’s Signature \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/image_test1.png', 'type': 'jpg'}, page_content='It was the best of\\ntimes, it was the worst\\nof times, it was the age\\nof wisdom, it was the\\nage of foolishness...\\n'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/image_test2.png', 'type': 'jpg'}, page_content='Tech Booms of the New Decade?\\n\\nSelected technology sector projections\\nas of December 2019\\n\\n$98.4b annual global artificial intelligence\\nrevenue by 2023 - CAGR of 28.5% (2019-2023)\\n\\n__ Smartphones with a\\n5G mobile subscription\\n\\n1.1%\\n&) -\\n\\nElectric vehicles sold annually\\n\\n2025 2030 2020 2025\\nloT: Number of devices connected to the internet —\\n320 38.6b 50.0b\\nJ L a\\n2018 2025 2030\\n\\nSources: IDC, BloombergNEF, Ericsson, Strategy Analytics\\n\\n©@OO Statista %\\n'),\n",
       " Document(metadata={'source': 'C:/Research Folder/LLM research/LLM projects/ocr_rag/Data/image_test2.png', 'type': 'jpg'}, page_content='a %\\n')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc263c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents stored successfully\n"
     ]
    }
   ],
   "source": [
    "# storing in vectorStore\n",
    "documents_storing_in_vectorDB(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f9b43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"ocr-rag\"\n",
    "def run_llms(query: str):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    docsearch = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)\n",
    "    chat = ChatOpenAI(verbose=True, temperature=0, model=\"gpt-4o-mini-2024-07-18\")\n",
    "\n",
    "    retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    stuff_documents_chain = create_stuff_documents_chain(chat, retrieval_qa_chat_prompt)\n",
    "\n",
    "    qa = create_retrieval_chain(\n",
    "        retriever=docsearch.as_retriever(),\n",
    "        combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "\n",
    "    result = qa.invoke(input={\"input\": query})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3c039d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global revenue of artificial intelligence is projected to be $98.4 billion by 2023.\n"
     ]
    }
   ],
   "source": [
    "# testing our Retrieval Augmented Generation\n",
    "res = run_llms(query=\"what is the global revenue of artificial intelligence?\")\n",
    "print(res[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
